{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fuzzy-condition",
   "metadata": {},
   "source": [
    "# Helper functions for Information Bottleneck with Confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "numeric-encoding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook smfile.ipynb to script\n",
      "[NbConvertApp] Writing 15811 bytes to smfile.py\n"
     ]
    }
   ],
   "source": [
    "#!jupyter nbconvert --to script smfile.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "chinese-planet",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from embo import InformationBottleneck\n",
    "import HMM_beads_utils as ut\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import spearmanr\n",
    "import seaborn as sns\n",
    "import os,ndd,pickle\n",
    "from adjustText import adjust_text\n",
    "cmap = plt.get_cmap(\"tab10\")\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "registered-overhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_previous_n_beads(w, x):\n",
    "    '''\n",
    "    Function that gets history of viewed beads\n",
    "    Input:\n",
    "        - w: number of past beads in history\n",
    "        - x: full sequence of beads\n",
    "    Output:\n",
    "        - history: array of strings of previous w beads\n",
    "    '''\n",
    "    numtrials = x.shape[0]\n",
    "    aux_base = 2**np.arange(w)\n",
    "    x_padded = np.empty(numtrials+w)\n",
    "    x_padded[:w] = 0\n",
    "    x_padded[w:] = x\n",
    "    history_bin = np.array([sum(aux_base * np.array(x_padded[i:(i + w)][::-1])) for i in np.arange(numtrials)])\n",
    "    return [np.binary_repr(int(z),w+1) for z in history_bin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "spiritual-welsh",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_windowed_x_v(xhist,z,w=1):\n",
    "    zw = z[w:].copy()\n",
    "    xw = np.array([int(h[1:][::-1],2) for h in xhist][w:])\n",
    "    return(xw,zw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "olive-active",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_between(s, first, last):\n",
    "    try:\n",
    "        start = s.index(first) + len(first)\n",
    "        end = s.index(last, start)\n",
    "        return s[start:end]\n",
    "    except ValueError:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "norman-journal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_sim_pred(sname,beads,jars,trials, p = 0.8,h = 0.01):\n",
    "    '''\n",
    "    Function to generate responses from the ideal observer with different internal estimates of p and h\n",
    "    INPUT:\n",
    "        - sname: subject identifier in data frame\n",
    "        - beads: 1D array of observed bead sequence\n",
    "        - jars: 1D array of jar sequence that generated beads\n",
    "        - p: internal model estimate of the probability that the bead will match the generating jar\n",
    "        - h_array: internal estimate of the hazard rate\n",
    "    OUTPUT:\n",
    "        -df: data frame with the following columns\n",
    "            - Subject: subject ID + simulation type (from no noise to lots of noise)\n",
    "            - Trial: trial number from start of experiment\n",
    "            - Jar: jar generating the bead\n",
    "            - Bead: bead observed on each trial\n",
    "            - Prior: prior probability that the the jar generating the next bead = 1 (before observing the bead)\n",
    "            - Posterior: posterior probability that the jar generating the last bead = 1 (after observing the bead)\n",
    "            - Prediction: simulated prediction\n",
    "    '''\n",
    "    \n",
    "    # Initialize\n",
    "    p_jars = np.array([.5,.5])              # Initial prior\n",
    "    likes = np.array([[p,(1-p)],[(1-p),p]]) # Likelihood\n",
    "    prior = np.zeros(len(beads))            # Initialize trial-by-trial priors\n",
    "    pred_hardmax = np.zeros(len(beads))     # Initialize hardmax predictions\n",
    "    posterior = np.zeros(len(beads))        # Initialize trial-by-trial posteriors\n",
    "    \n",
    "    # Loop through all trials and get simulated responses\n",
    "    for i in np.arange(len(beads)):\n",
    "        # Apply hazard rate\n",
    "        #h = h_array[i]\n",
    "        z1,z2 = tuple(p_jars.copy())\n",
    "        p_jars = [(1-h)*z1 + h*z2, (1-h)*z2 + h*z1]\n",
    "\n",
    "        #Save Prior\n",
    "        prior[i] = p_jars[1]\n",
    "        \n",
    "        # Incorporate likelihood\n",
    "        p_jars = p_jars*likes[int(beads[i])]\n",
    "        p_jars = p_jars/sum(p_jars)\n",
    "        \n",
    "        # Save posterios\n",
    "        posterior[i] = p_jars[1]\n",
    "        \n",
    "    # Get harmax predictions\n",
    "    pred_hardmax[prior!=.5] = np.array(prior[prior!=.5] > .5).astype(int)\n",
    "    pred_hardmax[prior==.5] = np.random.choice([0,1],size=len(prior[prior==.5]),replace=True)\n",
    "    \n",
    "    # Save data frame\n",
    "    df = pd.DataFrame({\n",
    "        'Subject':np.array([str(sname)+'_Ideal']*len(beads)),\n",
    "        'Trial':trials,\n",
    "        'Jar':jars,\n",
    "        'Bead':beads,\n",
    "        'Prior':prior,\n",
    "        'Posterior':posterior,\n",
    "        'Prediction':pred_hardmax\n",
    "    })\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "technological-archive",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test bounds in each session\n",
    "def get_windowed_mi(x_array,z,nw,confid = 0):\n",
    "    '''\n",
    "    Function that windows of observations from a sequence x offset from y and computes the MI\n",
    "    Input:\n",
    "        - x: sequence of \"past\" observations to be windowed\n",
    "        - z: sequence that serves as the \"future\" events\n",
    "        - nw: maximum window size\n",
    "    Output:\n",
    "        - mis: NSB estimated mutual informtion values for each window size\n",
    "    '''\n",
    "    mis = np.zeros(nw+1) #vector of mutual informations for different window sizes\n",
    "    for w in np.arange(1,nw+1):\n",
    "        xw,zw = get_windowed_x_v(['0' + h[-w:] for h in x_array],z,w=w)         # use convenience function from utilities to window x\n",
    "        mis[w] = ut.mutual_inf_nsb(xw,zw,[2**w,2+confid*2]) # use convenience function from utilities to compute NSB mutual info\n",
    "    return(mis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "declared-implement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_windowed_bound(x_array,z,w,mb=50,nb=2000,p=8, maxbeta = 5):\n",
    "    '''\n",
    "    Function that computes the information bottleneck bound between two discrete variables\n",
    "    Input:\n",
    "        - x: sequence of past events\n",
    "        - z: sequence of future events\n",
    "        - w: size of the window to be applied to x\n",
    "        - mb: maximum value of the lagrange multiplier beta\n",
    "        - nb: number of values of beta between 0 and mb to be run through the Blahaut-Arimoto algorithm\n",
    "        - p: number of cores to use in the computation (to help with speed)\n",
    "    Output:\n",
    "        - 4 element tuple with a sequence of ipast and ifuture values corresponding to the information bottleneck for full and one back bounds\n",
    "    '''\n",
    "    # Get desired windowed x and corresponding z\n",
    "    xw,zw = get_windowed_x_v(['0' + h[-w:] for h in x_array],z,w=w)\n",
    "    \n",
    "    # Compute the information bottleneck using EMBO for the window size w specified above\n",
    "    ipw, ifw, _, _= InformationBottleneck(xw, zw, window_size_x=1, window_size_y=1, maxbeta = maxbeta, numbeta=6*maxbeta).get_bottleneck()\n",
    "\n",
    "    # Compute the information bottleneck using EMBO for the window size w specified above\n",
    "    x1b,z1b = get_windowed_x_v(['0' + h[-1:] for h in x_array],z,w=1)\n",
    "    ip1b, if1b, _, _ = InformationBottleneck(x1b, z1b, window_size_x=1, window_size_y=1, maxbeta = maxbeta, numbeta=6*maxbeta).get_bottleneck()   \n",
    "    \n",
    "    # Return informtion bottleneck\n",
    "    return((ipw,ifw,ip1b,if1b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "flush-kingdom",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_windowed_mi_subs(sdat_all,nw):\n",
    "    '''\n",
    "    Function to compute windowed mutual information values for all subjects\n",
    "    Input:\n",
    "        - sdat_all: data frame with all of the subject tones, responses, and sources\n",
    "        - nw: maximum window size to be considered\n",
    "    Output:\n",
    "        - Ipast for each window size and Ifuture\n",
    "    '''\n",
    "    # Create dictionaries to keep track of variables with subject IDs as the keys\n",
    "    subs = pd.unique(sdat_all['Subject'])\n",
    "    ip_sub = {}\n",
    "    if_sub = {}\n",
    "    # Loop through each subject and get their Ipast for windows up to nw and their ifuture\n",
    "    for subi,sub in enumerate(subs):\n",
    "        sdat = sdat_all[sdat_all['Subject'] == sub]                   # Get data from specific subject \n",
    "        ip_sub[sub] = get_windowed_mi(sdat['History'],sdat['Response'],nw)    # compute Ipast using function defined above \n",
    "        if_sub[sub] = ut.mutual_inf_nsb(sdat['Response'],sdat['Jar'],[2,2]) # compute Ifuture\n",
    "    # Return dictionaries of ipast and ifuture values\n",
    "    return(ip_sub,if_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "meaning-roman",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bootstrapped_samples(dat,wips,nboot):\n",
    "    '''\n",
    "    Function to compute and return bootstrapped distributions of Ipast and Ifuture values for each subject\n",
    "    Input:\n",
    "        - dat: all subject data\n",
    "        - wips: matrix of mutual information by widow size values for each subject\n",
    "        - nboot: number of requested bootstrap iterations\n",
    "    Output:\n",
    "        - dictionaries of bootstrapped distributions of Ipast and Ifuture values\n",
    "    '''\n",
    "    # Get subject IDs and initialize dictionaries\n",
    "    subs = pd.unique(dat['Subject'])\n",
    "    ip_boot_mi = {}\n",
    "    if_boot_mi = {}\n",
    "    \n",
    "    # Loop through each subject and get bootstrapped estimates\n",
    "    for subi,sub in enumerate(subs):\n",
    "        sdat = dat[dat['Subject'] == sub]   # Get subject data\n",
    "        w = wips[sub].argmax()              # Get subject's maximum window size\n",
    "        x = np.array(sdat['History'])           # Get tones, responses, and sources for the subject\n",
    "        r = np.array(sdat['Response'])\n",
    "        z = np.array(sdat['Jar'])\n",
    "        xw,rw = get_windowed_x_v(['0' + h[-(w+1):] for h in x],r,w=(w+1)) # Window the tones and responses appropriately\n",
    "        ip_boot_mi[sub] = np.zeros(nboot)      # Initialize arrays of mutual information values\n",
    "        if_boot_mi[sub] = np.zeros(nboot)\n",
    "        \n",
    "        # Run bootstrap procedure\n",
    "        for boot in np.arange(nboot):\n",
    "            idx = np.random.choice(np.arange(len(xw)),size=len(xw),replace=True)    # Select random indicies with replacement\n",
    "            ip_boot_mi[sub][boot] = ut.mutual_inf_nsb(xw[idx],rw[idx],[2**(w+1),2]) # Use indexed data to compute Ipast\n",
    "            if_boot_mi[sub][boot] = ut.mutual_inf_nsb(r[idx],z[idx],[2,2])          # Use indexed data to compute Ifuture\n",
    "    # Return dictionaries of Ipast and Ifuture distributions\n",
    "    return(ip_boot_mi,if_boot_mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dated-punishment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_windowed_mi_subs_confid(sdat_all,nw):\n",
    "    '''\n",
    "    Function to compute windowed mutual information values for all subjects\n",
    "    Input:\n",
    "        - sdat_all: data frame with all of the subject tones, responses, and sources\n",
    "        - nw: maximum window size to be considered\n",
    "    Output:\n",
    "        - Ipast for each window size and Ifuture\n",
    "    '''\n",
    "    # Create dictionaries to keep track of variables with subject IDs as the keys\n",
    "    subs = pd.unique(sdat_all['Subject'])\n",
    "    ip_sub = {}\n",
    "    if_sub = {}    \n",
    "    # Loop through each subject and get their Ipast for windows up to nw and their ifuture\n",
    "    for subi,sub in enumerate(subs):\n",
    "        sdat = sdat_all[sdat_all['Subject'] == sub]                   # Get data from specific subject \n",
    "        ip_sub[sub] = get_windowed_mi(sdat['History'],2*sdat['Response'] + sdat['Confidence'],nw, confid = 1)    # compute Ipast using function defined above \n",
    "        if_sub[sub] = ut.mutual_inf_nsb(2*sdat['Response'] + sdat['Confidence'],sdat['Jar'],[4,2]) # compute Ifuture\n",
    "    # Return dictionaries of ipast and ifuture values\n",
    "    return(ip_sub,if_sub)\n",
    "\n",
    "\n",
    "\n",
    "def get_bootstrapped_samples_confid(dat,wips,nboot):\n",
    "    '''\n",
    "    Function to compute and return bootstrapped distributions of Ipast and Ifuture values for each subject\n",
    "    Input:\n",
    "        - dat: all subject data\n",
    "        - wips: matrix of mutual information by widow size values for each subject\n",
    "        - nboot: number of requested bootstrap iterations\n",
    "    Output:\n",
    "        - dictionaries of bootstrapped distributions of Ipast and Ifuture values\n",
    "    '''\n",
    "    # Get subject IDs and initialize dictionaries\n",
    "    subs = pd.unique(dat['Subject'])\n",
    "    ip_boot_mi = {}\n",
    "    if_boot_mi = {}\n",
    "    \n",
    "    # Loop through each subject and get bootstrapped estimates\n",
    "    for subi,sub in enumerate(subs):\n",
    "        sdat = dat[dat['Subject'] == sub]   # Get subject data\n",
    "        w = wips[sub].argmax()              # Get subject's maximum window size\n",
    "        x = np.array(sdat['History'])           # Get tones, responses, and sources for the subject\n",
    "        r = np.array(2*sdat['Response'] + sdat['Confidence'])\n",
    "        z = np.array(sdat['Jar'])\n",
    "        xw,rw = get_windowed_x_v(['0' + h[-(w+1):] for h in x],r,w=(w+1)) # Window the tones and responses appropriately\n",
    "        ip_boot_mi[sub] = np.zeros(nboot)      # Initialize arrays of mutual information values\n",
    "        if_boot_mi[sub] = np.zeros(nboot)\n",
    "            \n",
    "        # Run bootstrap procedure\n",
    "        for boot in np.arange(nboot):\n",
    "            idx = np.random.choice(np.arange(len(xw)),size=len(xw),replace=True)    # Select random indicies with replacement\n",
    "            ip_boot_mi[sub][boot] = ut.mutual_inf_nsb(xw[idx],rw[idx],[2**(w+1),4]) # Use indexed data to compute Ipast\n",
    "            if_boot_mi[sub][boot] = ut.mutual_inf_nsb(r[idx],z[idx],[4,2])\n",
    "    # Return dictionaries of Ipast and Ifuture distributions\n",
    "    return(ip_boot_mi,if_boot_mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "processed-hopkins",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_windowed_mi_subs_confo(sdat_all,nw):\n",
    "    '''\n",
    "    Function to compute windowed mutual information values for all subjects\n",
    "    Input:\n",
    "        - sdat_all: data frame with all of the subject tones, responses, and sources\n",
    "        - nw: maximum window size to be considered\n",
    "    Output:\n",
    "        - Ipast for each window size and Ifuture\n",
    "    '''\n",
    "    # Create dictionaries to keep track of variables with subject IDs as the keys\n",
    "    subs = pd.unique(sdat_all['Subject'])\n",
    "    ip_sub = {}\n",
    "    if_sub = {}\n",
    "    # Loop through each subject and get their Ipast for windows up to nw and their ifuture\n",
    "    for subi,sub in enumerate(subs):\n",
    "        sdat = sdat_all[sdat_all['Subject'] == sub]                   # Get data from specific subject \n",
    "        ip_sub[sub] = get_windowed_mi(sdat['History'],sdat['Confidence'],nw)    # compute Ipast using function defined above \n",
    "        if_sub[sub] = ut.mutual_inf_nsb(sdat['Confidence'],sdat['Jar'],[2,2]) # compute Ifuture\n",
    "    # Return dictionaries of ipast and ifuture values\n",
    "    return(ip_sub,if_sub)\n",
    "\n",
    "def get_bootstrapped_samples_confo(dat,wips,nboot):\n",
    "    '''\n",
    "    Function to compute and return bootstrapped distributions of Ipast and Ifuture values for each subject\n",
    "    Input:\n",
    "        - dat: all subject data\n",
    "        - wips: matrix of mutual information by widow size values for each subject\n",
    "        - nboot: number of requested bootstrap iterations\n",
    "    Output:\n",
    "        - dictionaries of bootstrapped distributions of Ipast and Ifuture values\n",
    "    '''\n",
    "    # Get subject IDs and initialize dictionaries\n",
    "    subs = pd.unique(dat['Subject'])\n",
    "    ip_boot_mi = {}\n",
    "    if_boot_mi = {}\n",
    "    \n",
    "    # Loop through each subject and get bootstrapped estimates\n",
    "    for subi,sub in enumerate(subs):\n",
    "        sdat = dat[dat['Subject'] == sub]   # Get subject data\n",
    "        w = wips[sub].argmax()              # Get subject's maximum window size\n",
    "        x = np.array(sdat['History'])           # Get tones, responses, and sources for the subject\n",
    "        r = np.array(sdat['Confidence'])\n",
    "        z = np.array(sdat['Jar'])\n",
    "        xw,rw = get_windowed_x_v(['0' + h[-(w+1):] for h in x],r,w=(w+1)) # Window the tones and responses appropriately\n",
    "        ip_boot_mi[sub] = np.zeros(nboot)      # Initialize arrays of mutual information values\n",
    "        if_boot_mi[sub] = np.zeros(nboot)\n",
    "            \n",
    "        # Run bootstrap procedure\n",
    "        for boot in np.arange(nboot):\n",
    "            idx = np.random.choice(np.arange(len(xw)),size=len(xw),replace=True)    # Select random indicies with replacement\n",
    "            ip_boot_mi[sub][boot] = ut.mutual_inf_nsb(xw[idx],rw[idx],[2**(w+1),2]) # Use indexed data to compute Ipast\n",
    "            if_boot_mi[sub][boot] = ut.mutual_inf_nsb(r[idx],z[idx],[2,2])\n",
    "    # Return dictionaries of Ipast and Ifuture distributions\n",
    "    return(ip_boot_mi,if_boot_mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-nowhere",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DTB(seq,ipast,ifuture,ip_fullbound = [],if_fullbound = []):\n",
    "    ''' \n",
    "    Function to calculate vertical distance from the bound between an empirical IB and participant predictive info\n",
    "    ipast: participant ipast (uncorrected)\n",
    "    ifuture: participant ifuture (uncorrected)\n",
    "    \n",
    "    Returns participant ifuture minus the empirical bound (more negative = farther away from the bound)\n",
    "    '''\n",
    "    if len(ip_fullbound) == 0: ip_fullbound,if_fullbound,_,_ = sm.get_windowed_bound(seq['History'],seq['Jar'],6,maxbeta = 7)\n",
    "    ind = np.argwhere(np.array(ip_fullbound) > ipast)[0][0]\n",
    "    slp = (if_fullbound[ind]-if_fullbound[ind-1])/(ip_fullbound[ind]-ip_fullbound[ind-1])\n",
    "    intercept = if_fullbound[ind]-(slp*ip_fullbound[ind])\n",
    "    #Return distance between participant Ifuture and interpolated bound\n",
    "    return ifuture - ((ipast*slp)+intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ultimate-impossible",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(x, level):\n",
    "    n = 1\n",
    "    #np.random.seed(17)\n",
    "    noise = np.random.binomial(n, 1-level, len(x))\n",
    "    return(np.where(x == noise,1,0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
